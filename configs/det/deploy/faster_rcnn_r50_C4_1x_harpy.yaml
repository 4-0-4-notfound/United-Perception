num_classes: &num_classes 81
class_names: &class_names [
    "__background__", "person", "bicycle", "car", "motorcycle", "airplane",
    "bus", "train", "truck", "boat", "traffic light", "fire hydrant",
    "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse",
    "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
    "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard",
    "sports ball", "kite", "baseball bat", "baseball glove", "skateboard",
    "surfboard", "tennis racket", "bottle", "wine glass", "cup", "fork",
    "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange",
    "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair",
    "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop",
    "mouse", "remote", "keyboard", "cell phone", "microwave", "oven",
    "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors",
    "teddy bear", "hair drier", "toothbrush"
]
runtime:
  task_names: det
to_kestrel:
  toks_type: det
  default_confidence_thresh: 0.0
  plugin: harpy   # choices = [essos, harpy, sphinx]
  model_name: model
  version: 1.0.0
  resize_hw: 800x1333

flip: &flip
 type: flip
 kwargs:
   flip_p: 0.5

resize: &train_resize
 type: keep_ar_resize
 kwargs:
   scales: [800]
   max_size: 1333
   separate_wh: True

test_resize: &test_resize
 type: keep_ar_resize
 kwargs:
   scales: [800]
   max_size: 1333
   separate_wh: True

to_tensor: &to_tensor
  type: to_tensor

normalize: &normalize
 type: normalize
 kwargs:
   mean: [0.485, 0.456, 0.406] # ImageNet pretrained statics
   std: [0.229, 0.224, 0.225]

dataset: # Required.
  train:
    dataset:
      type: coco
      kwargs:
        source: train  # dataset id
        class_names: *class_names
        meta_file: /mnt/lustre/share/DSK/datasets/mscoco2017/annotations/instances_train2017.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: /mnt/lustre/share/DSK/datasets/mscoco2017/train2017
            color_mode: RGB
        transformer: [*flip, *train_resize, *to_tensor, *normalize]
  test:
    dataset:
      type: coco
      kwargs:
        source: val
        meta_file: /mnt/lustre/share/DSK/datasets/mscoco2017/annotations/instances_val2017.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: /mnt/lustre/share/DSK/datasets/mscoco2017/val2017
            color_mode: RGB
        transformer: [*test_resize, *to_tensor, *normalize]
        evaluator:
          type: COCO               # choices = {'COCO', 'VOC', 'MR'}
          kwargs:
            gt_file: /mnt/lustre/share/DSK/datasets/mscoco2017/annotations/instances_val2017.json
            iou_types: [bbox]
  batch_sampler:
    type: aspect_ratio_group
    kwargs:
      sampler:
        type: dist
        kwargs: {}
      batch_size: 2
      aspect_grouping: [1,]
  dataloader:
    type: base
    kwargs:
      num_workers: 4
      alignment: 32
      pin_memory: True


trainer: # Required.
  max_epoch: 12              # total epochs for the training
  test_freq: 12
  optimizer:                 # optimizer = SGD(params,lr=0.001,momentum=0.9,weight_decay=0.0001)
    type: SGD
    kwargs:
      lr: 0.00125
      momentum: 0.9
      weight_decay: 0.0001
  lr_scheduler:              # lr_scheduler = MultStepLR(optimizer, milestones=[9,14],gamma=0.1)
    warmup_iter: 500         # set to be 0 to disable warmup. When warmup,  target_lr = init_lr * total_batch_size
    type: MultiStepLR
    kwargs:
      milestones: [8,11]     # epochs to decay lr
      gamma: 0.1             # decay rate

saver: # Required.
  save_dir: checkpoints/fs50-C4     # dir to save checkpoints
  pretrain_model: /mnt/lustre/share/DSK/model_zoo/pytorch/imagenet/resnet50-19c8e357.pth
  results_dir: results_dir/fs50-C4  # dir to save detection results. i.e., bboxes, masks, keypoints
  auto_resume: True # find last checkpoint from save_dir and resume from it automatically
                     # this option has the highest priority (auto_resume > opts > resume_model > pretrain_model)


hooks:
  - type: auto_checkpoint

net:
  - name: backbone              # backbone = resnet50(frozen_layers, out_layers, out_strides)
    type: resnet50
    kwargs:
      frozen_layers: [0,1]     # layer0...1 is fixed
      out_layers: [3]     # layer1...4, commonly named Conv2...5
      out_strides: [16]  # tell the strides of output features
      normalize:
        type: freeze_bn
      initializer:
        method: msra
  - name: roi_head
    prev: backbone 
    type: NaiveRPN
    kwargs:
      feat_planes: 512    # channels of intermediate conv
      num_classes: 2      # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
      num_anchors: 15
      class_activation: softmax
      num_level: 1
      initializer:
        method: normal
        std: 0.01
  - name: post_process
    prev: roi_head
    type: rpn_post
    kwargs:
      num_classes: 2  # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
      cfg:
        cls_loss:
          type: softmax_cross_entropy
          kwargs:
            class_dim: -1
        loc_loss:
          type: smooth_l1_loss
          kwargs:
            sigma: 3.0
        anchor_generator:
          type: hand_craft
          kwargs:
            anchor_ratios: [0.5,1,2]  # anchor strides are provided as feature strides by feature extractor
            anchor_scales: [2,4,8,16,32]        # scale of anchors relative to feature map
        roi_supervisor:
          type: rpn
          kwargs:
            allowed_border: 0
            matcher:
              type: max_iou
              kwargs:
                positive_iou_thresh: 0.7
                negative_iou_thresh: 0.3
                ignore_iou_thresh:   0.5
                allow_low_quality_match: True
                low_quality_thresh: 0.3  # !this option is not supported yet, but we have future plan
            sampler:
              type: naive
              kwargs:
                batch_size: 256
                positive_percent: 0.5
        train:
          roi_predictor:
            type: base
            kwargs:
              pre_nms_score_thresh: 0.0
              pre_nms_top_n: 12000
              post_nms_top_n: 2000
              roi_min_size: 0
              nms:
                type: naive
                nms_iou_thresh: 0.7
        test:
          roi_predictor:
            type: base
            kwargs:
              pre_nms_score_thresh: 0.0
              pre_nms_top_n: 6000
              post_nms_top_n: 300
              roi_min_size: 0
              nms:
                type: naive
                nms_iou_thresh: 0.7
  - name: bbox_head_pre_process
    type: BboxRes5_Pre
    kwargs:
      cfg:
        bbox_supervisor:
          type: faster
          kwargs:
            bbox_normalize: &bbox_norm
              means: [0, 0, 0, 0]         # statics to normalize localization predictions.
              stds: [0.1, 0.1, 0.2, 0.2] 
            matcher:
              type: max_iou
              kwargs:
                ignore_iou_thresh: 0.5          # Required if provide ignore_regions
                positive_iou_thresh: 0.5
                negative_iou_thresh: 0.5
                allow_low_quality_match: False  # positive if a anchor has highest iou with any gt
            sampler:
              type: naive
              kwargs:
                batch_size: 512
                positive_percent: 0.25
        roipooling: &roipooling
          method: 'roialignpool'      # choices=['roialignpool', 'psroipool', 'roipool', 'psroimaskpool']. note that 'psroipool' is for RFCN head
          pool_size: 7
          sampling_ratio: 0           # number of sampling points in each bin. 0 means densely sampled
  - name: bbox_head
    prev: backbone
    type: BboxRes5
    kwargs:
      backbone: resnet50
      normalize:
        type: freeze_bn
      num_classes: *num_classes                 # number of classification classes
      initializer:
        method: msra
      cfg:
        class_activation: softmax
        roipooling: *roipooling
        share_location: &share_location False         # is share location in bbox regression for all classes
  - name: bbox_head_post_process
    type: bbox_post
    kwargs:
      cfg:
        cls_loss:
          type: softmax_cross_entropy
          kwargs:
            class_dim: -1  # last dim is the class dim
        loc_loss:
          type: smooth_l1_loss
          kwargs:
            sigma: 1.0
        share_location: *share_location
        bbox_normalize: *bbox_norm
        bbox_predictor:
          type: faster
          kwargs:
            bbox_normalize: *bbox_norm
            share_location: *share_location
            nms:
              type: naive
              nms_iou_thresh: 0.5
            bbox_score_thresh: 0.0
            top_n: 100
